{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# df = pandas.read_csv('data/stability/stability_foldx_deduplicate_af2.csv')\n",
    "# df_sample = df.sample(frac=0.05)\n",
    "# df_sample.to_csv('data/stability/base_seq.csv', index=False)\n",
    "df = pd.read_csv('data/stability/stability_foldx_deduplicate_af2.csv')\n",
    "targets = df['target'].tolist()\n",
    "print(len(targets))\n",
    "print(np.mean(targets), np.median(targets), np.std(targets), np.max(targets), np.min(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def percentage_rank(nums, t):\n",
    "    sorted_nums = sorted(nums)\n",
    "    count = len(sorted_nums)\n",
    "    \n",
    "    if count == 0:\n",
    "        return None  # Return None if the list is empty\n",
    "    \n",
    "    for i, num in enumerate(sorted_nums):\n",
    "        if num >= t:\n",
    "            return (i / count) * 100\n",
    "    \n",
    "    return 100\n",
    "\n",
    "df = pd.read_csv('data/GFP/GFP_ground_truth_deduplicate.csv')\n",
    "print(len(df))\n",
    "ground_truth = df['target'].tolist()\n",
    "print(percentage_rank(ground_truth, 0.885))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('logs/train_smooth_stability_2023_09_11__14_44_27/samples/seed_1.csv')\n",
    "source_scores = df['source_scores'].values\n",
    "mutant_scores = df['mutant_scores'].values\n",
    "print(len(source_scores), len(mutant_scores))\n",
    "print(np.mean(source_scores), np.median(source_scores), np.std(source_scores), np.max(source_scores), np.min(source_scores))\n",
    "print(np.mean(mutant_scores), np.median(mutant_scores), np.std(mutant_scores), np.max(mutant_scores), np.min(mutant_scores))\n",
    "(source_scores < mutant_scores).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('logs/train_smooth_stability_2023_09_11__14_44_27/samples_20230913-144759/foldx_results.csv')\n",
    "scores = df['ddg'].values\n",
    "gt_csv = pd.read_csv('data/stability/base_seq.csv')\n",
    "gt_scores = gt_csv['target'].values\n",
    "print(np.mean(scores), np.median(scores), np.std(scores))\n",
    "print(np.mean(gt_scores), np.median(gt_scores), np.std(gt_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'abcd'\n",
    "y = 'abde'\n",
    "mut_site_indices = [i for i, aa in enumerate(y) if aa!= x[i]]\n",
    "mut_site_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sampled_data = pd.read_csv('logs/train_predictor_stability_2023_09_14__11_28_34_augment/samples_20230914-114542/foldx_results.csv')\n",
    "sampleds_seqs = set(sampled_data['sequence'].tolist())\n",
    "gt_data = pd.read_csv('data/stability/stability_foldx_deduplicate_af2.csv')\n",
    "gt_seqs = set(gt_data['sequence'].tolist())\n",
    "\n",
    "print(len(sampleds_seqs.intersection(gt_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('logs/GWG_2_2023_09_20__09_52_33_pareto/samples_20230920-095233/seed_1.csv')\n",
    "df['source_scores'] = df['source_scores_1']\n",
    "df['mutant_scores'] = df['mutant_scores_1']\n",
    "df.to_csv('logs/GWG_2_2023_09_20__09_52_33_pareto/samples_20230920-095233/seed_1_fill_stability.csv')\n",
    "df['source_scores'] = df['source_scores_2']\n",
    "df['mutant_scores'] = df['mutant_scores_2']\n",
    "df.to_csv('logs/GWG_2_2023_09_20__09_52_33_pareto/samples_20230920-095233/seed_1_fill_GFP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_scores'] = df['source_scores_2']\n",
    "df['mutant_scores'] = df['mutant_scores_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('logs/GWG_2_2023_09_19__11_40_04/samples_20230919-114004/seed_1_fillin_2_GFP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = torch.load('logs/oracle_GFP_ggs/checkpoints/best_checkpoints.pt')\n",
    "print(ckpt.keys())\n",
    "# keys = list(ckpt.keys())\n",
    "# for key in keys:\n",
    "#     ckpt[key[10:]] = ckpt.pop(key)\n",
    "# print(ckpt.keys())\n",
    "# state_dict = ckpt['state_dict']\n",
    "# torch.save(ckpt, 'logs/oracle_GFP_ggs/checkpoints/best_checkpoints.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/foldx/cache.json') as f:\n",
    "    a = json.load(f)\n",
    "print(a, type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.indicators.hv import HV\n",
    "import numpy as np\n",
    "from pymoo.problems import get_problem\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "# The pareto front of a scaled zdt1 problem\n",
    "pf = get_problem(\"zdt1\").pareto_front()\n",
    "\n",
    "# The result found by an algorithm\n",
    "A = pf\n",
    "print(A.shape)\n",
    "# print(A)\n",
    "\n",
    "ref_point = np.array([1.2, 1.2])\n",
    "\n",
    "ind = HV(ref_point=ref_point)\n",
    "print(\"HV\", ind(A))\n",
    "print(\"HV\", ind(A * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_GFP = pd.read_csv('data/GFP/GFP_ground_truth_deduplicate.csv')\n",
    "df_stability = pd.read_csv('data/stability/stability_foldx_deduplicate_af2.csv')\n",
    "seqs_GFP = df_GFP['sequence'].tolist()\n",
    "seqs_stability = df_stability['sequence'].tolist()\n",
    "scores_GFP = df_GFP['target'].tolist()\n",
    "scores_stability = df_stability['target'].tolist()\n",
    "df = pd.DataFrame({'sequence': seqs_GFP, \n",
    "                   'GFP': scores_GFP,\n",
    "                   'stability': scores_stability})\n",
    "df.to_csv('data/ground_truth_GFP_stability.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'seq': ['seq1', 'seq2', 'seq3', 'seq4'],\n",
    "    'GFP': [1.5, -0.5, -1.5, 2.0],\n",
    "    'stability': [0.5, 1.5, 2.5, 0.5]\n",
    "})\n",
    "\n",
    "# Filtering rows\n",
    "filtered_df = df[(df['GFP'] < 0) & (df['stability'] > 1)]\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def foldx_runner(batch_idx, pdb_dir, pdb_file, mut_file, out_dir, num_runs=5):\n",
    "    cmd = f'FoldX --command=BuildModel --pdb-dir={pdb_dir} --pdb={pdb_file} --output-dir={out_dir} --mutant-file={mut_file} --numberOfRuns={num_runs} --out-pdb=false --output-file=batch_{batch_idx}'\n",
    "    # os.system(cmd)\n",
    "    print(cmd)\n",
    "\n",
    "batch_idx = 2\n",
    "foldx_runner(batch_idx, 'data/foldx/outputs_af2', 'ref_seq_af2_Repair.pdb', f'tmp_foldx/tmp_2023-09-21_14-05-19/individual_list/individual_list_{batch_idx}.txt', 'tmp_foldx/tmp_2023-09-21_13-48-29', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/all_seqs_list.json') as f:\n",
    "    all_seqs_list = json.load(f)\n",
    "print(len(all_seqs_list), len(all_seqs_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "records = SeqIO.parse('data/foldx/GFP_reference_seq_aa.fasta', 'fasta')\n",
    "ref_seq = str(next(records).seq)\n",
    "print(ref_seq, len(ref_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_differences(seq1, seq2):\n",
    "    if len(seq1) != len(seq2):\n",
    "        raise ValueError(\"Both sequences must be of the same length.\")\n",
    "    \n",
    "    differences = []\n",
    "    for i, (s1, s2) in enumerate(zip(seq1, seq2)):\n",
    "        if s1 != s2:\n",
    "            differences.append(f\"{s1}{i+1}{s2}\")\n",
    "    \n",
    "    differences = ';'.join(differences)\n",
    "    \n",
    "    return differences\n",
    "\n",
    "all_seqs_difference = [sequence_differences(ref_seq, seq) for seq in all_seqs_list]\n",
    "print(all_seqs_difference[:10], len(all_seqs_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "starting = pd.read_csv('data/GFP_stability_percentile_0.4.csv').sequence.tolist()\n",
    "is_starting = [int(seq in starting) for seq in tqdm(all_seqs_list)]\n",
    "print(sum(is_starting))\n",
    "df = pd.DataFrame({'mutants': all_seqs_difference,\n",
    "                   'seq': all_seqs_list, \n",
    "                   'starting': is_starting})\n",
    "df.to_csv('data/GFP_stability_percentile_0.4_mutants.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils.eval import calc_hypervolume\n",
    "import numpy as np\n",
    "wt_GFP = 2.555\n",
    "wt_GFP_normalized = 0.448\n",
    "df = pd.read_csv('logs/GWG_2_2023_09_21__13_20_28_pareto/samples_20230921-132028/evaluation_results_2topk.csv')\n",
    "scores1 = df['stability_normalized'].values\n",
    "scores2 = 1 - df['GFP_normalized'].values\n",
    "# scores1 = np.clip(scores1, 0, 1)\n",
    "# scores2 = np.clip(scores2, 0, 1)\n",
    "print(scores1.shape, scores2.shape)\n",
    "\n",
    "r1, r2 = 1.0, 1.0\n",
    "hv = calc_hypervolume(scores1, scores2, r1, r2)\n",
    "print(hv)\n",
    "plt.scatter(scores1, scores2, s=2)\n",
    "plt.scatter([r1], [r2], c='r', marker='x')\n",
    "plt.scatter([0], [1 - wt_GFP_normalized], c='r', marker='x')\n",
    "plt.title('pareto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_hypervolume([0, 0.5], [0.5, 0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"SKGEELFTGVVPILVGLDGDVNGHKFSMSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLPYGVQRFSRYPDHDKQHGFFKSAMPEGYVQEGTIFFKDDGNYQTRAEVKFEGGTLVNRIELKGHDFKEDGNILGHKLEYNYNSHNVYIMADKQKDGIKVNFKIRHNIEDGSVQLADHYQQDTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDRMVLLEFVTAAGITHGMDEPYK\" == \"SKGEELFTGVVPILVGLDGDVNGHKFSMSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLPYGVQRFSRYPDHDKQHGFFKSAMPEGYVQEGTIFFKDDGNYQTRAEVKFEGGTLVNRIELKGHDFKEDGNILGHKLEYNYNSHNVYIMADKQKDGIKVNFKIRHNIEDGSVQLADHYQQDTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDRMVLLEFVTAAGITHGMDEPYK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils.eval import calc_hypervolume\n",
    "\n",
    "wt_GFP = 2.555\n",
    "wt_GFP_normalized = 0.448\n",
    "\n",
    "def draw_scatter_plot(csv_path, axs, title):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    scores1 = df['stability'].values\n",
    "    scores2 = df['GFP'].values\n",
    "    # scores1 = np.clip(scores1, 0, 1)\n",
    "    # scores2 = np.clip(scores2, 0, 1)\n",
    "    # print(scores1.shape, scores2.shape)\n",
    "\n",
    "    r1, r2 = 0, 0\n",
    "    hv = calc_hypervolume(-scores1, -scores2, r1, r2)\n",
    "    # print(hv)\n",
    "    axs.scatter(scores1, scores2, s=2)\n",
    "    axs.scatter([r1], [r2], c='r', marker='x')\n",
    "    axs.text(r1, r2, 'ref', fontsize=8, ha='right')\n",
    "    axs.scatter([68], [wt_GFP], c='r', marker='x')\n",
    "    axs.text(68, wt_GFP, 'wt', fontsize=8, ha='left')\n",
    "    axs.set_title(f'{title}, hv={hv:.3f}')\n",
    "    axs.set_xlabel('-stability')\n",
    "    axs.set_ylabel('GFP')\n",
    "    \n",
    "    return scores1.mean().item(), scores2.mean().item()\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6))\n",
    "avg_pts_x = []\n",
    "avg_pts_y = []\n",
    "legend = []\n",
    "x, y = draw_scatter_plot('logs/GWG_2_2023_09_21__13_20_28_pareto/samples_20230921-132028/evaluation_results_2topk.csv', axs[0, 0], 'pareto')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('pareto')\n",
    "x, y = draw_scatter_plot('logs_baseline/random_sample_GFP_2023_09_25__13_27_14_GFP/evaluation_results.csv', axs[0, 1], 'random on GFP')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('random on GFP')\n",
    "x, y = draw_scatter_plot('logs_baseline/random_sample_stability_2023_09_25__14_16_39/evaluation_results.csv', axs[0, 2], 'random on stability')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('random on stability')\n",
    "x, y = draw_scatter_plot('logs_baseline/simulated_annealing_GFP_2023_09_26__11_44_41/evaluation_results.csv', axs[1, 0], 'sa on GFP')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('sa on GFP')\n",
    "x, y = draw_scatter_plot('logs_baseline/simulated_annealing_stability_2023_09_26__11_51_21/evaluation_results.csv', axs[1, 1], 'sa on stability')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('sa on stability')\n",
    "x, y = draw_scatter_plot('logs/train_smooth_GFP_2023_09_21__17_01_05_agument/samples_20230921-194739/evaluation_results.csv', axs[1, 2], 'GWG+smooth on GFP')\n",
    "avg_pts_x.append(x)\n",
    "avg_pts_y.append(y)\n",
    "legend.append('GWG+smooth on GFP')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(avg_pts_x)))\n",
    "plt.scatter(avg_pts_x, avg_pts_y, color=colors)\n",
    "for i, txt in enumerate(legend):\n",
    "    plt.annotate(txt, (avg_pts_x[i], avg_pts_y[i]), fontsize=9, ha='right', va='bottom')\n",
    "plt.xlabel('stability')\n",
    "plt.ylabel('GFP')\n",
    "plt.title('average fitness')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gt_GFP_stability = pd.read_csv('data/ground_truth_GFP_stability_old.csv')\n",
    "print(len(gt_GFP_stability))\n",
    "print(gt_GFP_stability.head())\n",
    "new_stability = pd.read_csv('data/stability/Stability_foldx_deduplicate_new.csv')\n",
    "print(len(new_stability))\n",
    "print(new_stability.head())\n",
    "print(gt_GFP_stability['sequence'].tolist() == new_stability['sequence'].tolist())\n",
    "gt_GFP_stability['stability'] = new_stability['target']\n",
    "gt_GFP_stability.to_csv('data/ground_truth_GFP_stability.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data/GFP_stability_percentile_0.2_0.4.csv')\n",
    "data.head()\n",
    "stability = data['stability'].tolist()\n",
    "print(np.mean(stability), np.median(stability), np.std(stability), np.max(stability), np.min(stability))\n",
    "GFP = data['GFP'].tolist()\n",
    "print(np.mean(GFP), np.median(GFP), np.std(GFP), np.max(GFP), np.min(GFP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./logs_baseline_new/mala_approx_stability_2023_10_01__17_51_27/samples_seed_42.csv')\n",
    "df = df.drop_duplicates(subset=['mutant_sequences'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/GFP_stability_percentile_0.2_0.4.csv')\n",
    "stability = df['stability'].values\n",
    "gt = pd.read_csv('data/ground_truth_GFP_stability.csv')\n",
    "gt_stability = gt['stability'].values\n",
    "gt_min, gt_max = gt_stability.min(), gt_stability.max()\n",
    "print(gt_min, gt_max)\n",
    "normalized_stability = (stability - gt_min) / (gt_max - gt_min)\n",
    "print(normalized_stability)\n",
    "print(normalized_stability.mean(), normalized_stability.max(), normalized_stability.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils.eval import calc_hypervolume\n",
    "import numpy as np\n",
    "\n",
    "def get_point(metric_csv_path, column='median_fitness'):\n",
    "    df = pd.read_csv(metric_csv_path)\n",
    "    metrics = df[column].tolist()[-2:]\n",
    "    x, y = metrics[0], metrics[1]\n",
    "    return x, y\n",
    "\n",
    "labels = ['1.8_0.2', '1.5_0.5', '1.0_1.0', '0.5_1.5', '0.2_1.8', 'average', 'GWG_GFP', 'GWG_stable',  'adalead_GFP', '0.8_1.2',\n",
    "          '1.2_0.8', '0.9_1.1', '1.1_0.9']\n",
    "csv_path_list = ['./logs_new/GWG_2_2023_10_03__10_02_12_weight_1.8_0.2/samples_20231003-100212/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__09_45_59_weight_1.5_0.5/samples_20231003-094559/evaluation_metrics_nested_selection.csv',\n",
    "                 'logs_new/GWG_2_2023_09_30__16_13_27/samples_20230930-161327/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__09_46_26_weight_0.5_1.5/samples_20231003-094626/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__10_02_40_weight_0.2_1.8/samples_20231003-100240/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_01__10_37_47_avg_lambda_6/samples_20231001-103747/evaluation_metrics_nested_selection.csv',\n",
    "                 'logs_new/train_smooth_GFP_2023_09_30__13_34_58/samples_20230930-135740/evaluation_metrics.csv',\n",
    "                 'logs_new/train_predictor_stability_0.2_0.4_2023_09_30__10_43_49/samples_20230930-104911/evaluation_metrics.csv',\n",
    "                #  'logs_baseline_new/random_sample_GFP_2023_10_01__12_07_24_0.2_0.4/evaluation_metrics_single_task.csv',\n",
    "                #  'logs_baseline_new/random_sample_stability_2023_10_01__12_07_34_0.2_0.4/evaluation_metrics_single_task.csv',\n",
    "                 'logs_baseline_new/adalead_GFP_2023_10_02__16_52_36/evaluation_metrics_single_task.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__11_25_16_weight_0.8_1.2/samples_20231003-112516/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__11_24_40_weight_1.2_0.8/samples_20231003-112440/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__12_02_37_weight_0.9_1.1/samples_20231003-120237/evaluation_metrics_nested_selection.csv',\n",
    "                 './logs_new/GWG_2_2023_10_03__12_03_03_weight_1.1_0.9/samples_20231003-120303/evaluation_metrics_nested_selection.csv',]\n",
    "points = [get_point(csv_path) for csv_path in csv_path_list]\n",
    "stability_scores, GFP_scores = zip(*points)\n",
    "# print(stability_scores)\n",
    "# print(GFP_scores)\n",
    "reverse_stability_scores = np.array(stability_scores)\n",
    "GFP_scores = np.array(GFP_scores)\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=100)\n",
    "plt.scatter(reverse_stability_scores, GFP_scores, s=12)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    plt.annotate(labels[i], (reverse_stability_scores[i], GFP_scores[i]), fontsize=9, xytext=(reverse_stability_scores[i]-0.3, GFP_scores[i]+0.02))\n",
    "\n",
    "plt.xlabel('stability')\n",
    "plt.ylabel('GFP fitness')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.read_csv('data/gb1/four_mutations_full_data.csv')\n",
    "selected = pd.DataFrame({'sequence': df['sequence'],\n",
    "                         'target': df['Fitness']})\n",
    "selected.to_csv('data/gb1/ground_truth_gb1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = 'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTELEVLFQGPLDPNSMATYEVLCEVARKLGTDDREVVLFLLNVFIPQPTLAQLIGALRALKEEGRLTFPLLAECLFRAGRRDLLRDLLHLDPRFLERHLAGTMSYFSPYQLTVLHVDGELCARDIRSLIFLSKDTIGSRSTPQTFLHWVYCMENLDLLGPTDVDALMSMLRSLSRVDLQRQVQTLMGLHLSGPSHSQHYRHTPLEHHHHHH'\n",
    "pdb = 'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTELEVLFQGPLDPNSMATYEVLCEVARKLGTDDREVVLFLLNVFIPQPTLAQLIGALRALKEEGRLTFPLLAECLFRAGRRDLLRDLLHLDPRFLERHLAGTMSYFSPYQLTVLHVDGELCARDIRSLIFLSKDTIGSRSTPQTFLHWVYCMENLDLLGPTDVDALMSMLRSLSRVDLQRQVQTLMGLHLSGPSHSQHYRHTPLEHHHHHH'\n",
    "print([s for s in wt])\n",
    "print(len(wt))\n",
    "print(wt[38], wt[39], wt[40], wt[53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mut = 'VA39M,DA40D,GA41D,VA54V;'\n",
    "root_dir = '/work/kerr/p450/mutation/results/GB1/foldx/all'\n",
    "for i in range(16000):\n",
    "    with open(os.path.join(root_dir, str(i), 'individual_list.txt')) as f:\n",
    "        lines = f.read()\n",
    "        if mut in lines:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_duplicates(ll):\n",
    "    elements_count = Counter(ll)\n",
    "    duplicates = [k for k, v in elements_count.items() if v > 1]\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "gb1 = pd.read_csv('data/gb1/ground_truth_gb1.csv')\n",
    "gb1_seqs = gb1['sequence'].tolist()\n",
    "print(len(gb1_seqs), len(set(gb1_seqs)))\n",
    "gb1_targets = gb1['target'].tolist()\n",
    "gb1_seq2target = dict(zip(gb1_seqs, gb1_targets))\n",
    "ddg = pd.read_csv('data/gb1/ground_truth_ddg.csv')\n",
    "ddg_seqs = ddg['sequence'].tolist()\n",
    "print(len(ddg_seqs), len(set(ddg_seqs)))\n",
    "ddg_targets = ddg['target'].tolist()\n",
    "ddg_seq2target = dict(zip(ddg_seqs, ddg_targets))\n",
    "print(f'ddg_seq2target: {len(ddg_seq2target)}')\n",
    "duplicates = get_duplicates(ddg_seqs)\n",
    "print(len(duplicates))\n",
    "print(duplicates[:10])\n",
    "print(len(set(gb1_seqs)))\n",
    "print(set(gb1_seqs).intersection(set(ddg_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGMDDEWTYDDATKTFTVTELEVLFQGPLDPNSMATYEVLCEVARKLGTDDREVVLFLLNVFIPQPTLAQLIGALRALKEEGRLTFPLLAECLFRAGRRDLLRDLLHLDPRFLERHLAGTMSYFSPYQLTVLHVDGELCARDIRSLIFLSKDTIGSRSTPQTFLHWVYCMENLDLLGPTDVDALMSMLRSLSRVDLQRQVQTLMGLHLSGPSHSQHYRHTPLEHHHHHH'\n",
    "s[38], s[39], s[40], s[53]\n",
    "mut = 'VA39M,DA40D,GA41D,VA54V;'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser, is_aa\n",
    "from Bio.SeqUtils import seq1\n",
    "\n",
    "parser = PDBParser()\n",
    "structure = parser.get_structure('data/gb1/5LDE_A.pdb', 'data/gb1/5LDE_A.pdb')\n",
    "print(structure[0]['A'])\n",
    "chain = structure[0]['A']\n",
    "sequence = []\n",
    "for res in chain:\n",
    "    if is_aa(res, standard=True):\n",
    "        sequence.append(seq1(res.get_resname()))\n",
    "sequence = ''.join(sequence)\n",
    "print(sequence)\n",
    "print(len(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('data/gb1/ground_truth_ddg_part1.csv')\n",
    "df2 = pd.read_csv('data/gb1/ground_truth_ddg_part2.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "deduplicated = df.drop_duplicates(subset=['sequence'], keep='first')\n",
    "len(deduplicated)\n",
    "deduplicated.to_csv('data/gb1/ground_truth_ddg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_duplicates(ll):\n",
    "    elements_count = Counter(ll)\n",
    "    duplicates = [k for k, v in elements_count.items() if v > 1]\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "gb1 = pd.read_csv('data/gb1/ground_truth_gb1.csv')\n",
    "gb1_seqs = gb1['sequence'].tolist()\n",
    "print(len(gb1_seqs), len(set(gb1_seqs)))\n",
    "gb1_targets = gb1['target'].tolist()\n",
    "gb1_seq2target = dict(zip(gb1_seqs, gb1_targets))\n",
    "ddg = pd.read_csv('data/gb1/ground_truth_ddg.csv')\n",
    "ddg_seqs = ddg['sequence'].tolist()\n",
    "print(len(ddg_seqs), len(set(ddg_seqs)))\n",
    "ddg_targets = ddg['target'].tolist()\n",
    "ddg_seq2target = dict(zip(ddg_seqs, ddg_targets))\n",
    "print(f'ddg_seq2target: {len(ddg_seq2target)}')\n",
    "duplicates = get_duplicates(ddg_seqs)\n",
    "print(len(duplicates))\n",
    "print(duplicates[:10])\n",
    "print(len(set(gb1_seqs)))\n",
    "print(set(gb1_seqs).intersection(set(ddg_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
